{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import plot, iplot, init_notebook_mode\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from filterpy.kalman import unscented_transform, MerweScaledSigmaPoints\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "import random\n",
    "from sklearn.cluster import KMeans\n",
    "from itertools import chain\n",
    "\n",
    "from filterpy.kalman import unscented_transform, MerweScaledSigmaPoints\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('./dataset/MNIST5_new_train_x.npy')\n",
    "Y_train = np.load('./dataset/MNIST5_new_train_y.npy')\n",
    "X_test = np.load('./dataset/MNIST5_new_test_x.npy')\n",
    "Y_test = np.load('./dataset/MNIST5_new_test_y.npy')\n",
    "print(X_train.shape, Y_train.shape);print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space_train = np.load('./dataset/MNIST5_train_latent_space_z5.npy')\n",
    "print(latent_space_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "latent_space_test = np.load('./dataset/MNIST5_test_latent_space_z5.npy')\n",
    "print(latent_space_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [{'kernel': ['rbf'], 'C' : [0.1, 1, 10, 100]},\n",
    "                    {'kernel': ['linear'], 'C' : [0.1, 1, 10, 100]}]\n",
    "# ,\n",
    "#                    {'kernel': ['poly'], 'C' : [0.1, 1, 10, 100], 'gamma': [1,0.1,0.01,0.001]},\n",
    "#                    {'kernel': ['sigmoid'], 'C' : [0.1, 1, 10, 100], 'gamma': [1,0.1,0.01,0.001]}]\n",
    "score = 'accuracy'\n",
    "clf = GridSearchCV(SVC(), tuned_parameters, scoring=score, n_jobs=-1,refit=True,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# z=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform_is = np.load('./result/mean_accuracy_rs_MNIST5_input_space.npy')\n",
    "uniform_is_sd = np.load('./result/sd_accuracy_rs_MNIST5_input_space.npy')\n",
    "\n",
    "uniform_ls = np.load('./result/mean_accuracy_rs_MNIST5_z5.npy')\n",
    "uniform_ls_sd = np.load('./result/sd_accuracy_rs_MNIST5_z5.npy')\n",
    "\n",
    "random_coreset_is40 = np.load('./result/mean_accuracy_cs_MNIST5_input_space_K40.npy')\n",
    "random_coreset_is40_sd = np.load('./result/sd_accuracy_cs_MNIST5_input_space_K40.npy')\n",
    "\n",
    "random_coreset_ls40 = np.load('./result/mean_accuracy_cs_MNIST5_z5_K40.npy')\n",
    "random_coreset_ls40_sd = np.load('./result/sd_accuracy_cs_MNIST5_z5_K40.npy')\n",
    "\n",
    "sensitivity_ls40 = np.load('./result/mean_accuracy_Kraus_cs1000_MNIST5_z5_K40.npy')\n",
    "sensitivity_ls40_sd = np.load('./result/sd_accuracy_Kraus_cs1000_MNIST5_z5_K40.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniform_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [uniform_ls[4*i+3] for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "number_of_labeled_data = range(40,501,40)\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "\n",
    "plt.plot(number_of_labeled_data,uniform_is, marker='o', markersize=10)\n",
    "plt.plot(number_of_labeled_data,uniform_ls, marker='*', markersize=10)\n",
    "plt.plot(number_of_labeled_data,random_coreset_is40, marker='X', markersize=10)\n",
    "plt.plot(number_of_labeled_data,random_coreset_ls40, marker='D', markersize=10) \n",
    "plt.plot(number_of_labeled_data,sensitivity_ls40, marker='s', markersize=10)\n",
    "\n",
    "\n",
    "plt.fill_between(number_of_labeled_data, (uniform_is - uniform_is_sd), (uniform_is + uniform_is_sd), alpha=.1)\n",
    "plt.fill_between(number_of_labeled_data, (uniform_ls - uniform_ls_sd), (uniform_ls + uniform_ls_sd), alpha=.1)\n",
    "plt.fill_between(number_of_labeled_data, (random_coreset_is40 - random_coreset_is40_sd), (random_coreset_is40 + random_coreset_is40_sd), alpha=.1)\n",
    "plt.fill_between(number_of_labeled_data, (random_coreset_ls40 - random_coreset_ls40_sd), (random_coreset_ls40 + random_coreset_ls40_sd), alpha=.1)\n",
    "plt.fill_between(number_of_labeled_data, (sensitivity_ls40 - sensitivity_ls40_sd), (sensitivity_ls40 + sensitivity_ls40_sd), alpha=.1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.legend(['input space (uniform)',         \n",
    "            'latent space (uniform)',\n",
    "          'input space (Random Coreset)',\n",
    "            'latent space (Random Coreset)'\\\n",
    "           ,'latent space (Sensitivity Sampling)'\n",
    "           ], loc = 4, fontsize=25)\n",
    "plt.grid()\n",
    "plt.xticks(number_of_labeled_data)\n",
    "plt.xlabel(\"Number of labelled points\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy comparison for 500 labeled points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_components = np.arange(1, 161)\n",
    "models = [GaussianMixture(n, covariance_type='full', random_state=0).fit(latent_space_train) #z=7\n",
    "          for n in n_components]\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.grid()\n",
    "plt.plot(n_components, [m.bic(latent_space_train) for m in models], label='BIC')\n",
    "plt.plot(n_components, [m.aic(latent_space_train) for m in models], label='AIC')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.xlabel('n_components');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmin([m.bic(latent_space_train) for m in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmin([m.aic(latent_space_train) for m in models])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM + UT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filterpy.kalman import unscented_transform, MerweScaledSigmaPoints\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gmm = GaussianMixture(n_components=20).fit(latent_space_train)\n",
    "gmm = GaussianMixture(n_components=80).fit(latent_space_train)\n",
    "labels = gmm.predict(latent_space_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Counter(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gmm.covariances_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm.means_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_sigmas = []\n",
    "for i in range(80):#range(20):\n",
    "    mean = gmm.means_[i]\n",
    "    p = gmm.covariances_[i]\n",
    "    points = MerweScaledSigmaPoints(n=5, alpha=0.1, beta=2., kappa=(3-5))\n",
    "    sigmas = points.sigma_points(mean, p)\n",
    "    all_sigmas.append(sigmas)\n",
    "    #print(sigmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sigmas = np.array(all_sigmas, dtype=np.float32)\n",
    "all_sigmas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sigma_points = all_sigmas.reshape(80*11,5)\n",
    "sigma_points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE DUPLICATE SIGMA POINTS\n",
    "sigma_points = np.unique(sigma_points, axis=0)\n",
    "sigma_points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fig = go.Figure()\n",
    "\n",
    "# fig.add_trace(go.Scatter3d(x=sigma_points[:,0], y=sigma_points[:,1], \\\n",
    "#                                    z=sigma_points[:,2], mode='markers',\\\n",
    "#                                   marker=dict(\n",
    "#         size=2,\n",
    "#         color='black',                # set color to an array/list of desired values\n",
    "#        # colorscale='Viridis',   # choose a colorscale\n",
    "#         opacity=1.0\n",
    "#     )))\n",
    "\n",
    "# fig.add_trace(go.Scatter3d(x=latent_space_train[:,0], y=latent_space_train[:,1], z=latent_space_train[:,2], mode='markers',\\\n",
    "#                                   marker=dict(\n",
    "#         size=1,\n",
    "#         color='yellow',#kmeans.labels_,                # set color to an array/list of desired values\n",
    "#        # colorscale='Viridis',   # choose a colorscale\n",
    "#         opacity=0.5\n",
    "#     )))\n",
    "\n",
    "\n",
    "# fig.update_layout(\n",
    "#     autosize=False,\n",
    "#     width=1000,\n",
    "#     height=1000)\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def closest_node(node, nodes):\n",
    "#     dist_2 = np.sum((nodes - node)**2, axis=1)\n",
    "#     return np.argmin(dist_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find class of sigma point\n",
    "In order to find the class of sigma points we use KNN with Squared Euclidean Distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=1,weights='distance')\n",
    "neigh.fit(latent_space_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = neigh.predict(sigma_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Counter(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_random = []\n",
    "sd_random = []\n",
    "\n",
    "\n",
    "for coreset_size in range(40,501,40):\n",
    "    print(\"*********************** Training on {} points ***********************\".format(coreset_size))\n",
    "    accuracy = [] # calculate accuracy of 500 iterations\n",
    "    c = list(zip(sigma_points,prediction))\n",
    "    iterations = 0\n",
    "    while iterations < 500: # run 500 simulations and take average \n",
    "        train_data = []\n",
    "        train_labels = []\n",
    "        for (data,label) in random.sample(c,coreset_size):\n",
    "            train_data.append(data)\n",
    "            train_labels.append(label)  \n",
    "        train_x = np.array(train_data)\n",
    "        train_y = np.array(train_labels)\n",
    "        \n",
    "        print()\n",
    "        print(\"Distribution of data in the training points\")\n",
    "        print(Counter(train_y)) \n",
    "\n",
    "        clf.fit(train_x, train_y)\n",
    "        print(\"Best parameters set found on {} data points:\".format(coreset_size))\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        y_true, y_pred = Y_test, clf.predict(latent_space_test)\n",
    "        accuracy.append(accuracy_score(y_true, y_pred))\n",
    "        iterations += 1\n",
    "    accuracy = np.asarray(accuracy)\n",
    "    mean_accuracy = accuracy.mean()\n",
    "    sd_accuracy = accuracy.std()\n",
    "    \n",
    "    mean_random.append(mean_accuracy)\n",
    "    sd_random.append(sd_accuracy)\n",
    "    \n",
    "mean_random = np.array(mean_random)\n",
    "sd_random = np.array(sd_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_random.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./result/mean_accuracy_MNIST5_sigma_random_alpha_0_1_N_80.npy',mean_random)\n",
    "np.save('./result/sd_accuracy_MNIST5_sigma_random_alpha_0_1_N_80.npy',sd_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 500 labeled points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sigma_knn_mean = np.load('./result/mean_accuracy_MNIST5_sigma_alpha_0_1_N_80.npy')\n",
    "sigma_knn_sd = np.load('./result/sd_accuracy_MNIST5_sigma_alpha_0_1_N_80.npy')\n",
    "\n",
    "mean_random = np.load('./result/mean_accuracy_MNIST5_sigma_random_alpha_0_1_N_80.npy')\n",
    "sd_random = np.load('./result/sd_accuracy_MNIST5_sigma_random_alpha_0_1_N_80.npy')\n",
    "\n",
    "\n",
    "number_of_labeled_data = range(40,257,40)\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "# plt.plot(number_of_labeled_data,uniform_ls,'go--',linewidth=1, markersize=10, mfc='none') \n",
    "# plt.plot(number_of_labeled_data,random_coreset_ls50,'r*-.',linewidth=1, markersize=10, mfc='none')\n",
    "# plt.plot(number_of_labeled_data,sensitivity_ls50,'ms-',linewidth=1, markersize=10, mfc='none')\n",
    "plt.plot(number_of_labeled_data,sigma_knn_mean,'b^:',linewidth=1, markersize=10, mfc='none')\n",
    "plt.plot(number_of_labeled_data,mean_random,'ms-',linewidth=1, markersize=10, mfc='none')\n",
    "\n",
    "# plt.fill_between(number_of_labeled_data, (uniform_ls - uniform_ls_sd), (uniform_ls + uniform_ls_sd), alpha=.1, color = 'g')\n",
    "# plt.fill_between(number_of_labeled_data, (random_coreset_ls50 - random_coreset_ls50_sd), (random_coreset_ls50 + random_coreset_ls50_sd), alpha=.1, color = 'r')\n",
    "# plt.fill_between(number_of_labeled_data, (sensitivity_ls50 - sensitivity_ls50_sd), (sensitivity_ls50 + sensitivity_ls50_sd), alpha=.1, color = 'm')\n",
    "plt.fill_between(number_of_labeled_data, (sigma_knn_mean - sigma_knn_sd), (sigma_knn_mean + sigma_knn_sd), alpha=.1, color = 'b')\n",
    "plt.fill_between(number_of_labeled_data, (mean_random - sd_random), (mean_random + sd_random), alpha=.1, color = 'm')\n",
    "\n",
    "\n",
    "\n",
    "plt.legend([         \n",
    "#             'Uniform coreset sampling',\n",
    "#             'Random coreset sampling',\n",
    "#             'Sensitivity coreset sampling',\n",
    "            'Trained on real data',  'Trained on sigma points'\n",
    "           ], loc = 4, fontsize=20)\n",
    "                 \n",
    "plt.grid()\n",
    "plt.xticks(number_of_labeled_data, fontsize = 15, rotation = 90)\n",
    "plt.yticks(fontsize = 20)\n",
    "plt.xlabel(\"Number of labelled points\", fontsize = 20)\n",
    "plt.ylabel(\"Accuracy\", fontsize = 20)\n",
    "plt.savefig('./analysis/MNIST5_0_1_N_80_comparison_of_real_vs_sigma.pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=40, random_state=0).fit(sigma_points)\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(Counter(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train a model to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_random = []\n",
    "sd_random = []\n",
    "\n",
    "for coreset_size in range(40,441,40): # start from 1000 labeled points\n",
    "    print(\"*********************** Training on {} points ***********************\".format(coreset_size))\n",
    "\n",
    "    accuracy = []\n",
    "    m = int(coreset_size/40) # m=B/K, number of points from each cluster\n",
    "    iterations = 0\n",
    "    while iterations < 500: # run 100 simulations and take average \n",
    "        train_data = []\n",
    "        train_labels = []\n",
    "        indices_to_pick = []\n",
    "        \n",
    "        print(\"Choosing {} points from each cluster\".format(m))\n",
    "        for cluster_index in range(40):\n",
    "            C_i = np.where(labels == cluster_index)[0].tolist()\n",
    "            sample_i = random.sample(C_i, m)\n",
    "            indices_to_pick.append(sample_i)\n",
    "        \n",
    "        indices_to_pick = list(chain.from_iterable(indices_to_pick)) # flatten the 2D list\n",
    "        \n",
    "        assert len(indices_to_pick)==coreset_size, \"Sample size mismatch!!!!\"\n",
    "        \n",
    "        for index in indices_to_pick:\n",
    "            train_data.append(sigma_points[index])\n",
    "            train_labels.append(prediction[index]) \n",
    "        \n",
    "        train_x = np.array(train_data)\n",
    "        train_y = np.array(train_labels)\n",
    "        \n",
    "        print()\n",
    "        print(\"Distribution of data in the training points\")\n",
    "        print(Counter(train_y))\n",
    "\n",
    "        clf.fit(train_x, train_y)\n",
    "        print(\"Best parameters set found on {} data points:\".format(coreset_size))\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        y_true, y_pred = Y_test, clf.predict(latent_space_test)\n",
    "        accuracy.append(accuracy_score(y_true, y_pred))\n",
    "        iterations += 1\n",
    "\n",
    "    accuracy = np.asarray(accuracy)\n",
    "    mean_accuracy = accuracy.mean()\n",
    "    sd_accuracy = accuracy.std()\n",
    "\n",
    "\n",
    "    mean_random.append(mean_accuracy)\n",
    "    sd_random.append(sd_accuracy)\n",
    "    \n",
    "mean_random = np.array(mean_random)\n",
    "sd_random = np.array(sd_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_random.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./result/mean_accuracy_MNIST5_sigma_KNN_alpha_0_9_N_80.npy',mean_random)\n",
    "np.save('./result/sd_accuracy_MNIST5_sigma_KNN_alpha_0_9_N_80.npy',sd_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sigma_knn_mean1 = np.load('./result/mean_accuracy_MNIST5_sigma_KNN_alpha_0_1_N_80.npy')\n",
    "sigma_knn_sd1 = np.load('./result/sd_accuracy_MNIST5_sigma_KNN_alpha_0_1_N_80.npy')\n",
    "\n",
    "sigma_knn_mean3 = np.load('./result/mean_accuracy_MNIST5_sigma_KNN_alpha_0_3_N_80.npy')\n",
    "sigma_knn_sd3 = np.load('./result/sd_accuracy_MNIST5_sigma_KNN_alpha_0_3_N_80.npy')\n",
    "\n",
    "sigma_knn_mean5 = np.load('./result/mean_accuracy_MNIST5_sigma_KNN_alpha_0_5_N_80.npy')\n",
    "sigma_knn_sd5 = np.load('./result/sd_accuracy_MNIST5_sigma_KNN_alpha_0_5_N_80.npy')\n",
    "\n",
    "sigma_knn_mean7 = np.load('./result/mean_accuracy_MNIST5_sigma_KNN_alpha_0_7_N_80.npy')\n",
    "sigma_knn_sd7 = np.load('./result/sd_accuracy_MNIST5_sigma_KNN_alpha_0_7_N_80.npy')\n",
    "\n",
    "sigma_knn_mean9 = np.load('./result/mean_accuracy_MNIST5_sigma_KNN_alpha_0_9_N_80.npy')\n",
    "sigma_knn_sd9 = np.load('./result/sd_accuracy_MNIST5_sigma_KNN_alpha_0_9_N_80.npy')\n",
    "\n",
    "\n",
    "number_of_labeled_data = range(40,441,40)\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "plt.plot(number_of_labeled_data,sigma_knn_mean1,'go--',linewidth=1, markersize=10, mfc='none') \n",
    "plt.plot(number_of_labeled_data,sigma_knn_mean3,'r*-.',linewidth=1, markersize=10, mfc='none')\n",
    "plt.plot(number_of_labeled_data,sigma_knn_mean5,'ms-',linewidth=1, markersize=10, mfc='none')\n",
    "plt.plot(number_of_labeled_data,sigma_knn_mean7,'b^:',linewidth=1, markersize=10, mfc='none')\n",
    "plt.plot(number_of_labeled_data,sigma_knn_mean9,'cx:',linewidth=1, markersize=10, mfc='none')\n",
    "\n",
    "# plt.fill_between(number_of_labeled_data, (sigma_knn_mean1 - sigma_knn_sd1), (sigma_knn_mean1 + sigma_knn_sd1), alpha=.1, color = 'g')\n",
    "# plt.fill_between(number_of_labeled_data, (sigma_knn_mean3 - sigma_knn_sd3), (sigma_knn_mean3 + sigma_knn_sd3), alpha=.1, color = 'r')\n",
    "# plt.fill_between(number_of_labeled_data, (sigma_knn_mean5 - sigma_knn_sd5), (sigma_knn_mean5 + sigma_knn_sd5), alpha=.1, color = 'm')\n",
    "# plt.fill_between(number_of_labeled_data, (sigma_knn_mean7 - sigma_knn_sd7), (sigma_knn_mean7 + sigma_knn_sd7), alpha=.1, color = 'b')\n",
    "# plt.fill_between(number_of_labeled_data, (sigma_knn_mean9 - sigma_knn_sd9), (sigma_knn_mean9 + sigma_knn_sd9), alpha=.1, color = 'c')\n",
    "\n",
    "\n",
    "\n",
    "plt.legend([         \n",
    "            r'$\\alpha = 0.1$',\n",
    "            r'$\\alpha = 0.3$',\n",
    "            r'$\\alpha = 0.5$',\n",
    "            r'$\\alpha = 0.7$',\n",
    "            r'$\\alpha = 0.9$'\n",
    "           ], loc = 4, fontsize=35)\n",
    "                 \n",
    "plt.grid()\n",
    "plt.xticks(number_of_labeled_data, fontsize = 25, rotation = 45)\n",
    "plt.yticks(fontsize = 25)\n",
    "plt.xlabel(\"Number of labelled points\", fontsize = 25)\n",
    "plt.ylabel(\"Accuracy\", fontsize = 25)\n",
    "plt.savefig('./analysis/MNIST5_trained-on-sigma-with-kmeans_comparison_alpha_N_80_test.pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 400 labeled points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniform_is = [uniform_is[2*i+1] for i in range(10)]\n",
    "# uniform_is_sd = [uniform_is_sd[2*i+1] for i in range(10)]\n",
    "# uniform_is = np.array(uniform_is)\n",
    "# uniform_is_sd = np.array(uniform_is_sd)\n",
    "\n",
    "# uniform_ls = [uniform_ls[2*i+1] for i in range(10)]\n",
    "# uniform_ls_sd = [uniform_ls_sd[2*i+1] for i in range(10)]\n",
    "# uniform_ls = np.array(uniform_ls)\n",
    "# uniform_ls_sd = np.array(uniform_ls_sd)\n",
    "\n",
    "\n",
    "# random_coreset_is40 = [random_coreset_is40[2*i+1] for i in range(10)]\n",
    "# random_coreset_is40_sd = [random_coreset_is40_sd[2*i+1] for i in range(10)]\n",
    "# random_coreset_is40 = np.array(random_coreset_is40)\n",
    "# random_coreset_is40_sd = np.array(random_coreset_is40_sd)\n",
    "\n",
    "# random_coreset_ls40 = [random_coreset_ls40[2*i+1] for i in range(10)]\n",
    "# random_coreset_ls40_sd = [random_coreset_ls40_sd[2*i+1] for i in range(10)]\n",
    "# random_coreset_ls40 = np.array(random_coreset_ls40)\n",
    "# random_coreset_ls40_sd = np.array(random_coreset_ls40_sd)\n",
    "\n",
    "# sensitivity_ls40 = [sensitivity_ls40[2*i+1] for i in range(10)]\n",
    "# sensitivity_ls40_sd = [sensitivity_ls40_sd[2*i+1] for i in range(10)]\n",
    "# sensitivity_ls40 = np.array(sensitivity_ls40)\n",
    "# sensitivity_ls40_sd = np.array(sensitivity_ls40_sd)\n",
    "\n",
    "\n",
    "uniform_is = uniform_is[:11]\n",
    "uniform_is_sd = uniform_is_sd[:11]\n",
    "uniform_ls = uniform_ls[:11]\n",
    "uniform_ls_sd = uniform_ls_sd[:11]\n",
    "random_coreset_is40 = random_coreset_is40[:11]\n",
    "random_coreset_is40_sd = random_coreset_is40_sd[:11]\n",
    "random_coreset_ls40 = random_coreset_ls40[:11]\n",
    "random_coreset_ls40_sd = random_coreset_ls40_sd[:11]\n",
    "sensitivity_ls40 = sensitivity_ls40[:11]\n",
    "sensitivity_ls40_sd = sensitivity_ls40_sd[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_knn_mean = np.load('./result/mean_accuracy_MNIST5_sigma_KNN_alpha_0_7_N_80.npy')\n",
    "sigma_knn_sd = np.load('./result/sd_accuracy_MNIST5_sigma_KNN_alpha_0_7_N_80.npy')\n",
    "\n",
    "\n",
    "number_of_labeled_data = range(40,441,40)\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "plt.plot(number_of_labeled_data,uniform_ls,'go--',linewidth=1, markersize=10, mfc='none') \n",
    "plt.plot(number_of_labeled_data,random_coreset_ls40,'r*-.',linewidth=1, markersize=10, mfc='none')\n",
    "plt.plot(number_of_labeled_data,sensitivity_ls40,'ms-',linewidth=1, markersize=10, mfc='none')\n",
    "plt.plot(number_of_labeled_data,sigma_knn_mean,'b^:',linewidth=1, markersize=10, mfc='none')\n",
    "\n",
    "plt.fill_between(number_of_labeled_data, (uniform_ls - uniform_ls_sd), (uniform_ls + uniform_ls_sd), alpha=.1, color = 'g')\n",
    "plt.fill_between(number_of_labeled_data, (random_coreset_ls40 - random_coreset_ls40_sd), (random_coreset_ls40 + random_coreset_ls40_sd), alpha=.1, color = 'r')\n",
    "plt.fill_between(number_of_labeled_data, (sensitivity_ls40 - sensitivity_ls40_sd), (sensitivity_ls40 + sensitivity_ls40_sd), alpha=.1, color = 'r')\n",
    "plt.fill_between(number_of_labeled_data, (sigma_knn_mean - sigma_knn_sd), (sigma_knn_mean + sigma_knn_sd), alpha=.1, color = 'b')\n",
    "\n",
    "\n",
    "\n",
    "plt.legend([         \n",
    "            'Uniform coreset sampling',\n",
    "            'Random coreset sampling',\n",
    "            'Sensitivity coreset sampling',\n",
    "            'Sigma point coreset sampling' \n",
    "           ], loc = 4, fontsize=20)\n",
    "                 \n",
    "plt.grid()\n",
    "plt.xticks(number_of_labeled_data, fontsize = 25, rotation = 45)\n",
    "plt.yticks(fontsize = 25)\n",
    "plt.xlabel(\"Number of labelled points\", fontsize = 25)\n",
    "plt.ylabel(\"Accuracy\", fontsize = 25)\n",
    "plt.savefig('./analysis/MNIST5_0_7_N_80_trained-on-sigma-with-kmeans_comparison.pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "number_of_labeled_data = range(40,501,40)\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "\n",
    "plt.plot(number_of_labeled_data, uniform_is, marker='o', markersize=10)\n",
    "plt.plot(number_of_labeled_data, uniform_ls, marker='*', markersize=10)\n",
    "plt.plot(number_of_labeled_data, random_coreset_is40, marker='X', markersize=10)\n",
    "plt.plot(number_of_labeled_data, random_coreset_ls40, marker='D', markersize=10) \n",
    "plt.plot(number_of_labeled_data, sensitivity_ls40, marker='s', markersize=10) \n",
    "plt.plot(number_of_labeled_data,mean_random, marker='^', markersize=10) \n",
    "\n",
    "\n",
    "plt.fill_between(number_of_labeled_data, (uniform_is - uniform_is_sd), (uniform_is + uniform_is_sd), alpha=.1)\n",
    "plt.fill_between(number_of_labeled_data, (uniform_ls - uniform_ls_sd), (uniform_ls + uniform_ls_sd), alpha=.1)\n",
    "plt.fill_between(number_of_labeled_data, (random_coreset_is40 - random_coreset_is40_sd), (random_coreset_is40 + random_coreset_is40_sd), alpha=.1)\n",
    "plt.fill_between(number_of_labeled_data, (random_coreset_ls40 - random_coreset_ls40_sd), (random_coreset_ls40 + random_coreset_ls40_sd), alpha=.1)\n",
    "plt.fill_between(number_of_labeled_data, (sensitivity_ls40 - sensitivity_ls40_sd), (sensitivity_ls40 + sensitivity_ls40_sd), alpha=.1)\n",
    "plt.fill_between(number_of_labeled_data, (mean_random - sd_random), (mean_random + sd_random), alpha=.1)\n",
    "\n",
    "\n",
    "plt.legend(['input space (uniform)',         \n",
    "            'latent space (uniform)',\n",
    "          'input space (Random Coreset)',\n",
    "            'latent space (Random Coreset)'\\\n",
    "             ,'latent space (Sensitivity Sampling)'\\\n",
    "          ,'latent space (Sigma Point Sampling)' \n",
    "           ], loc = 4, fontsize=25)\n",
    "plt.grid()\n",
    "plt.xticks(number_of_labeled_data)\n",
    "plt.xlabel(\"Number of labelled points\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "#plt.title(\"KNN | alpha= 0.7 | 120 components | z=5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
